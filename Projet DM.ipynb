{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0414f6d9",
   "metadata": {},
   "source": [
    "# Projet DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adf31586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.26.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\santi\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\santi\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 3.7/16.3 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 11.3/16.3 MB 32.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 16.3/16.3 MB 31.1 MB/s  0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "!pip install spacy\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4d840f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def load_jsonl(filename):\n",
    "    \"\"\"Load a .jsonl file. Tries both the given path and the 'data' folder.\n",
    "    Returns a list of dicts.\"\"\"\n",
    "    p = os.path.join('data', filename)\n",
    "    if os.path.exists(p):\n",
    "        data = []\n",
    "        with open(p, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    data.append(json.loads(line))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing a line in {p}: {e}\")\n",
    "        return data\n",
    "    raise FileNotFoundError(f\"File not found: {filename} (tried: {p})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04bdd7",
   "metadata": {},
   "source": [
    "### 1. Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2c64e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train records: 492, Test records: 519\n",
      "-- Train head --\n",
      "                                                text acronym  \\\n",
      "0  LRA  limite de résistance des attelages PAR po...     PAR   \n",
      "1                              Désigna -tion des PN       PN   \n",
      "2  prédéterminées de trains : _x0001_ les masses ...      EM   \n",
      "3  /Commentaires N° AC B81500 thermique:  compati...      AC   \n",
      "4  kilomètres/heure (ex : 12 pour 120 km/h), _x00...     TIV   \n",
      "\n",
      "                                             options  \n",
      "0  {'Plan d'action régularité': False, 'Poste d'a...  \n",
      "1  {'Passages à niveau : fichier des pn, recensem...  \n",
      "2  {'EMERAINVILLE PONTAULT COMBAULT': False, 'Eng...  \n",
      "3  {'ACcès': False, 'Agent d'aCcompagnement ': Fa...  \n",
      "4  {'THIVIERS': False, 'Trafic international voya...  \n",
      "\n",
      "-- Info --\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 492 entries, 0 to 491\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     492 non-null    object\n",
      " 1   acronym  492 non-null    object\n",
      " 2   options  492 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "train_path = 'train_v2.jsonl'\n",
    "test_path = 'test_v4.jsonl'\n",
    "\n",
    "train_data = load_jsonl(train_path)\n",
    "test_data = load_jsonl(test_path)\n",
    "\n",
    "print(f\"Train records: {len(train_data)}, Test records: {len(test_data)}\")\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Quick preview\n",
    "print(\"-- Train head --\")\n",
    "print(train_df.head())\n",
    "print(\"\\n-- Info --\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ccd4a2",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "784b460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['text', 'acronym', 'options']\n",
      "Missing values per column:\n",
      " text       0\n",
      "acronym    0\n",
      "options    0\n",
      "dtype: int64\n",
      "After cleaning, shape: (492, 3)\n"
     ]
    }
   ],
   "source": [
    "# Basic cleaning and review\n",
    "# 1) Columns, types, and missing values\n",
    "print(\"Columns:\", list(train_df.columns))\n",
    "print(\"Missing values per column:\\n\", train_df.isna().sum())\n",
    "\n",
    "# 2) Remove simple duplicates\n",
    "train_df = train_df.drop_duplicates(subset=['text', 'acronym']).reset_index(drop=True)\n",
    "\n",
    "# 3) Fill missing values in text columns with empty string (example)\n",
    "for col in train_df.select_dtypes(include='object').columns:\n",
    "    train_df[col] = train_df[col].fillna('')\n",
    "\n",
    "print(\"After cleaning, shape:\", train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac1be1",
   "metadata": {},
   "source": [
    "### 3. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f16f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text before normalization:\n",
      "['− Entreprises titulaires d’une attestation de sécurité et exerçant des activités relatives à la gestion de l\\'infrastructure − Etablissement Infra Circulation Centre : Pôle Sécurité, COGC Centre, BHR Centre, Gares et Postes concernés   Métier \"Maintenance & Travaux\" '\n",
      " 'CSS central sous-stations DAAT Dispositif d’arrêt automatique des trains DT double traction EAS équipement agent seul EF entreprise ferroviaire '\n",
      " \"EF entreprise ferroviaire EM engin moteur EPSF établissement public de sécurité ferroviaire GID gestionnaire d'infrastructure délégué HLP haut le pied \"]\n",
      "After text normalization, shape: (492, 3)\n",
      "Sample text after normalization:\n",
      "['bif 2 lyon / 2 biszone telecommandee par le pcd de dijonfa'\n",
      " 'amec autorisation de mise en exploitation commerciale dt double traction ef entreprise ferroviaire em engin moteur hlp haut le pied '\n",
      " \"cclr chef circulation local regulateur centre de circulation cle consigne locale d'exploitation cogc centre operationnel de gestion des circulations css central sous-stations eas equipement agent seul \"]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Remove OCR artifacts and bad characters\n",
    "def clean_ocr_artifacts(text):\n",
    "    # Remove _x0001_ and similar hex patterns\n",
    "    text = re.sub(r'_x[0-9a-fA-F]{4}_', '', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "print(\"Sample text before normalization:\")\n",
    "print(train_df['text'].sample(3).values)\n",
    "# Text normalization lowercasing\n",
    "for col in ['text', 'acronym']:\n",
    "    train_df[col] = train_df[col].str.lower()\n",
    "train_df['options'] = train_df['options'].apply(lambda opts: {k.lower(): v for k, v in opts.items()})\n",
    "# clean ocr artefacts\n",
    "for col in ['text', 'acronym']:\n",
    "    train_df[col] = train_df[col].apply(clean_ocr_artifacts)\n",
    "train_df['options'] = train_df['options'].apply(lambda opts: {clean_ocr_artifacts(k): v for k, v in opts.items()})\n",
    "\n",
    "#Apply unidecode to remove accents\n",
    "for col in ['text', 'acronym']:\n",
    "    train_df[col] = train_df[col].apply(lambda x: unidecode(x).encode('latin1').decode('latin1'))\n",
    "train_df['options'] = train_df['options'].apply(lambda opts: {unidecode(k).encode('latin1').decode('latin1'): v for k, v in opts.items()})\n",
    "\n",
    "print(\"After text normalization, shape:\", train_df.shape)\n",
    "print(\"Sample text after normalization:\")\n",
    "print(train_df['text'].sample(3).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5d17d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acronym</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lra  limite de resistance des attelages par po...</td>\n",
       "      <td>par</td>\n",
       "      <td>{'plan d'action regularite': False, 'poste d'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>designa -tion des pn</td>\n",
       "      <td>pn</td>\n",
       "      <td>{'passages a niveau : fichier des pn, recensem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predeterminees de trains : _x0001_ les masses ...</td>\n",
       "      <td>em</td>\n",
       "      <td>{'emerainville pontault combault': False, 'eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/commentaires ndeg ac b81500 thermique:  compa...</td>\n",
       "      <td>ac</td>\n",
       "      <td>{'acces': False, 'agent d'accompagnement ': Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kilometres/heure (ex : 12 pour 120 km/h), _x00...</td>\n",
       "      <td>tiv</td>\n",
       "      <td>{'thiviers': False, 'trafic international voya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>teur des quais est &gt;= 760 mm.] [ 1500v : (lyon...</td>\n",
       "      <td>us</td>\n",
       "      <td>{'us (val-d'oise)': False, 'unite simple : mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>serie consideree sans risque de deterioration ...</td>\n",
       "      <td>rff</td>\n",
       "      <td>{'roscoff': False, 'reseau ferre de france': T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>figurant pas dans la cle propre a l'etablissem...</td>\n",
       "      <td>cle</td>\n",
       "      <td>{'clermont ferrand': False, 'consigne locale d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>km fin restrictions me120 me100 ma100 830000 l...</td>\n",
       "      <td>cmt</td>\n",
       "      <td>{'controle des mobiles travaux': False, 'contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>de boudin ou de rails les engins moteurs tract...</td>\n",
       "      <td>cle</td>\n",
       "      <td>{'clermont ferrand': False, 'consigne locale d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text acronym  \\\n",
       "0    lra  limite de resistance des attelages par po...     par   \n",
       "1                                designa -tion des pn       pn   \n",
       "2    predeterminees de trains : _x0001_ les masses ...      em   \n",
       "3    /commentaires ndeg ac b81500 thermique:  compa...      ac   \n",
       "4    kilometres/heure (ex : 12 pour 120 km/h), _x00...     tiv   \n",
       "..                                                 ...     ...   \n",
       "487  teur des quais est >= 760 mm.] [ 1500v : (lyon...      us   \n",
       "488  serie consideree sans risque de deterioration ...     rff   \n",
       "489  figurant pas dans la cle propre a l'etablissem...     cle   \n",
       "490  km fin restrictions me120 me100 ma100 830000 l...     cmt   \n",
       "491  de boudin ou de rails les engins moteurs tract...     cle   \n",
       "\n",
       "                                               options  \n",
       "0    {'plan d'action regularite': False, 'poste d'a...  \n",
       "1    {'passages a niveau : fichier des pn, recensem...  \n",
       "2    {'emerainville pontault combault': False, 'eng...  \n",
       "3    {'acces': False, 'agent d'accompagnement ': Fa...  \n",
       "4    {'thiviers': False, 'trafic international voya...  \n",
       "..                                                 ...  \n",
       "487  {'us (val-d'oise)': False, 'unite simple : mod...  \n",
       "488  {'roscoff': False, 'reseau ferre de france': T...  \n",
       "489  {'clermont ferrand': False, 'consigne locale d...  \n",
       "490  {'controle des mobiles travaux': False, 'contr...  \n",
       "491  {'clermont ferrand': False, 'consigne locale d...  \n",
       "\n",
       "[492 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1a86993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\santi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\santi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading stopwords-fr: Package 'stopwords-fr' not\n",
      "[nltk_data]     found in index\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"stopwords-fr\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = stopwords.words(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "590f8d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stopword removal, shape: (492, 4)\n"
     ]
    }
   ],
   "source": [
    "#delete stop_words\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "train_df['text_clean'] = train_df['text'].apply(remove_stopwords)\n",
    "print(\"After stopword removal, shape:\", train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39f2f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After lemmatization:\n",
      "[\"lra  limite de resistance des attelages par poste d'aiguillage et de regulation pl pleine ligne pn passage a niveau rfn reseau ferre national \"\n",
      " '  designa -tion des pn '\n",
      " \"predeterminees de trains : _x0001_ les masses admissibles standard pour les trains (et eventuellement celles pour les trains entiers) pour chaque serie ou groupement de series d'em autorises a circuler sur tout ou partie du domaine couvert par le document, _x0001_ la limite de resistance des attelages standard [en distinguant eventuellement avec \"\n",
      " '/commentaires ndeg ac b81500 thermique:  compatibilite : oui/restrictions : les agc sont interdits a la desserte commerciale des etablis-sements dont la hauteur des quais est >= 760 mm '\n",
      " \"kilometres/heure (ex : 12 pour 120 km/h), _x0001_ d'une lettre indiquant le respect ou non des tableaux indicateurs de vitesse de type c (c respecte les tiv, n ne respecte pas les tiv). engin moteur vehicule ayant la capacite de se deplacer par ses propres moyens \"]\n",
      "['lra limite resistance attelage poste aiguillage regulation pl pleine lign pn passage niveau rfn reseau ferre national'\n",
      " 'designa pn'\n",
      " 'predeterminee train masse admissible standard train eventuellement train entier serie groupement serie em autorise circuler partie domaine couvrir document limite resistance attelage standard distinguer eventuellement'\n",
      " 'ndeg ac thermique compatibilite oui restriction agc interdire desserte commercial etablis sement hauteur quai millimètre'\n",
      " 'kilometre heure e kilomètre heure lettre indiquer respect non tableau indicateur vitesse type c c respecter tiv n respecter tiv engin moteur vehicule capacite deplacer propre moyen']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization setup\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "# Apply lemmatization\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(str(text))\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])\n",
    "\n",
    "train_df['text_clean'] = train_df['text'].apply(lemmatize_text)\n",
    "print(\"After lemmatization:\")\n",
    "print(train_df['text'].head(5).values)\n",
    "print(train_df['text_clean'].head(5).values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
